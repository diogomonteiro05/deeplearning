{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and Import Libraries\n",
    "Code to install the required libraries (diffusers, torch, torchvision, matplotlib) and import them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T13:53:25.292472Z",
     "iopub.status.busy": "2025-04-05T13:53:25.291659Z",
     "iopub.status.idle": "2025-04-05T13:53:50.228344Z",
     "shell.execute_reply": "2025-04-05T13:53:50.227606Z",
     "shell.execute_reply.started": "2025-04-05T13:53:25.292428Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install diffusers torch torchvision matplotlib\n",
    "\n",
    "# Import necessary libraries\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from diffusers import DDPMScheduler, UNet2DModel\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset\n",
    "Define transformations and create a dataset using ImageFolder with the specified dataroot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T13:53:50.229937Z",
     "iopub.status.busy": "2025-04-05T13:53:50.229425Z",
     "iopub.status.idle": "2025-04-05T13:55:20.298504Z",
     "shell.execute_reply": "2025-04-05T13:55:20.297716Z",
     "shell.execute_reply.started": "2025-04-05T13:53:50.229904Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define data transformations\n",
    "transform=transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# Set the dataset root directory\n",
    "dataroot = \"/kaggle/input/wiki-dataset/wiki\"\n",
    "\n",
    "# Create the dataset\n",
    "dataset = ImageFolder(root=dataroot, transform=transform)\n",
    "\n",
    "# Check the number of samples in the dataset\n",
    "print(f\"Number of images in the dataset: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Data Loader\n",
    "Initialize the DataLoader with parameters like batch_size and shuffle for batching the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T13:55:20.299981Z",
     "iopub.status.busy": "2025-04-05T13:55:20.299721Z",
     "iopub.status.idle": "2025-04-05T13:55:20.305295Z",
     "shell.execute_reply": "2025-04-05T13:55:20.304422Z",
     "shell.execute_reply.started": "2025-04-05T13:55:20.299961Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Initialize DataLoader\n",
    "batch_size = 16  # Define batch size\n",
    "shuffle = True   # Shuffle the dataset for training\n",
    "\n",
    "# Create DataLoader for batching\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "# Check the number of batches\n",
    "num_batches = len(dataloader)\n",
    "print(f\"Number of batches: {num_batches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Diffusion Model and Trainer\n",
    "Instantiate the UNet2DModel, set up the noise scheduler, and define the optimizer and initial training configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T13:55:20.306627Z",
     "iopub.status.busy": "2025-04-05T13:55:20.306366Z",
     "iopub.status.idle": "2025-04-05T13:55:21.603105Z",
     "shell.execute_reply": "2025-04-05T13:55:21.602122Z",
     "shell.execute_reply.started": "2025-04-05T13:55:20.306600Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the diffusion model\n",
    "model = UNet2DModel(\n",
    "    sample_size=64,  # Image size\n",
    "    in_channels=3,   # Number of input channels (RGB)\n",
    "    out_channels=3,  # Number of output channels (RGB)\n",
    "    layers_per_block=2,\n",
    "    block_out_channels=(128, 256, 512, 512),\n",
    "    down_block_types=(\n",
    "        \"DownBlock2D\", \"DownBlock2D\", \"DownBlock2D\", \"AttnDownBlock2D\"\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"AttnUpBlock2D\", \"UpBlock2D\", \"UpBlock2D\", \"UpBlock2D\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Define the noise scheduler\n",
    "noise_scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 15  # Number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop\n",
    "Implement the loop to iterate over data batches, add noise, predict noise, and update model weights. Note: This section appears twice in the notebook, but only one implementation is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T13:55:21.604363Z",
     "iopub.status.busy": "2025-04-05T13:55:21.604074Z",
     "iopub.status.idle": "2025-04-05T14:05:11.594461Z",
     "shell.execute_reply": "2025-04-05T14:05:11.593767Z",
     "shell.execute_reply.started": "2025-04-05T13:55:21.604333Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    for step, (images, _) in enumerate(dataloader):\n",
    "        # Move images to the device\n",
    "        images = images.to(device)\n",
    "\n",
    "        # Sample noise\n",
    "        noise = torch.randn_like(images).to(device)\n",
    "\n",
    "        # Sample random timesteps\n",
    "        timesteps = torch.randint(0, noise_scheduler.num_train_timesteps, (images.shape[0],), device=device).long()\n",
    "\n",
    "        # Add noise to the images\n",
    "        noisy_images = noise_scheduler.add_noise(images, noise, timesteps)\n",
    "\n",
    "        # Predict the noise\n",
    "        noise_pred = model(noisy_images, timesteps).sample\n",
    "\n",
    "        # Compute loss (mean squared error)\n",
    "        loss = torch.nn.functional.mse_loss(noise_pred, noise)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print loss every 100 steps\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step {step}/{len(dataloader)}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate and Display Images\n",
    "After training, set the model to evaluation mode, generate images using the reverse diffusion process, and display them using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T14:05:11.595510Z",
     "iopub.status.busy": "2025-04-05T14:05:11.595219Z",
     "iopub.status.idle": "2025-04-05T14:06:23.831154Z",
     "shell.execute_reply": "2025-04-05T14:06:23.830236Z",
     "shell.execute_reply.started": "2025-04-05T14:05:11.595476Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Generate and display images after training using the correct de-noising loop\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "with torch.no_grad():\n",
    "    num_images = 16  # Total images to generate\n",
    "    rows, cols = 4, 4  # 4x4 grid\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))\n",
    "    axes = axes.flatten()  # Flatten the array to iterate easily\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Start from random noise with the same size as training images (64x64 with 3 channels)\n",
    "        noisy_image = torch.randn(1, 3, 64, 64).to(device)\n",
    "        \n",
    "        # Reverse diffusion process\n",
    "        for t in reversed(range(noise_scheduler.num_train_timesteps)):\n",
    "            # Get noise prediction from the model\n",
    "            noise_pred = model(noisy_image, t).sample  \n",
    "            # Perform a de-noising step using the predicted noise\n",
    "            step_output = noise_scheduler.step(noise_pred, t, noisy_image)\n",
    "            noisy_image = step_output.prev_sample\n",
    "        \n",
    "        # Denormalize and prepare image for display\n",
    "        generated_image = (noisy_image.squeeze().cpu().numpy().transpose(1, 2, 0) * 0.5 + 0.5).clip(0, 1)\n",
    "        axes[i].imshow(generated_image)\n",
    "        axes[i].axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T14:15:19.460576Z",
     "iopub.status.busy": "2025-04-05T14:15:19.460260Z",
     "iopub.status.idle": "2025-04-05T14:15:19.480431Z",
     "shell.execute_reply": "2025-04-05T14:15:19.479492Z",
     "shell.execute_reply.started": "2025-04-05T14:15:19.460549Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import scipy.linalg\n",
    "\n",
    "class InceptionV3Feature(nn.Module):\n",
    "    \"\"\"\n",
    "    Extract features from the InceptionV3 model for FID calculation.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(InceptionV3Feature, self).__init__()\n",
    "        inception = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT)\n",
    "        self.features = nn.Sequential(\n",
    "            inception.Conv2d_1a_3x3,\n",
    "            inception.Conv2d_2a_3x3,\n",
    "            inception.Conv2d_2b_3x3,\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            inception.Conv2d_3b_1x1,\n",
    "            inception.Conv2d_4a_3x3,\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            inception.Mixed_5b,\n",
    "            inception.Mixed_5c,\n",
    "            inception.Mixed_5d,\n",
    "            inception.Mixed_6a,\n",
    "            inception.Mixed_6b,\n",
    "            inception.Mixed_6c,\n",
    "            inception.Mixed_6d,\n",
    "            inception.Mixed_6e,\n",
    "            inception.Mixed_7a,\n",
    "            inception.Mixed_7b,\n",
    "            inception.Mixed_7c,\n",
    "            inception.avgpool  # This gives [B, 2048, 1, 1]\n",
    "        )\n",
    "        self.eval()\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.shape[2] != 299 or x.shape[3] != 299:\n",
    "            x = F.interpolate(x, size=(299, 299), mode='bilinear', align_corners=False)\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten from [B, 2048, 1, 1] to [B, 2048]\n",
    "        return x\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.path = path\n",
    "        self.image_files = []\n",
    "\n",
    "        # Recursively gather image files from subdirectories\n",
    "        for root, _, files in os.walk(self.path):\n",
    "            for f in files:\n",
    "                if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.webp')):\n",
    "                    self.image_files.append(os.path.join(root, f))\n",
    "\n",
    "        if len(self.image_files) == 0:\n",
    "            raise ValueError(f\"No images found in directory: {self.path}\")\n",
    "\n",
    "        self.transform = transform if transform is not None else Compose([\n",
    "            Resize(64),\n",
    "            CenterCrop(64),\n",
    "            ToTensor(),\n",
    "            Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "def extract_features(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Extract features from all images in the dataloader.\n",
    "    \"\"\"\n",
    "    features_list = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = batch.to(device)\n",
    "            features = model(batch)\n",
    "            features_list.append(features.cpu().numpy())\n",
    "    \n",
    "    return np.concatenate(features_list, axis=0)\n",
    "\n",
    "def calculate_statistics(features):\n",
    "    \"\"\"\n",
    "    Calculate mean and covariance statistics of features.\n",
    "    \"\"\"\n",
    "    mu = np.mean(features, axis=0)\n",
    "    sigma = np.cov(features, rowvar=False)\n",
    "    return mu, sigma\n",
    "\n",
    "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Calculate Fr√©chet distance between two multivariate Gaussians.\n",
    "    \"\"\"\n",
    "    # Calculate squared difference between means\n",
    "    diff = mu1 - mu2\n",
    "    \n",
    "    # Product of covariances sqrt\n",
    "    # Handle numerical instability by adding small constant to diagonal\n",
    "    covmean, _ = scipy.linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    if not np.isfinite(covmean).all():\n",
    "        print(\"WARNING: FID calculation produces singular product; adding jitter to diagonal\")\n",
    "        offset = np.eye(sigma1.shape[0]) * eps\n",
    "        covmean = scipy.linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
    "    \n",
    "    # Numerical precision issues can cause small imaginary parts\n",
    "    if np.iscomplexobj(covmean):\n",
    "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
    "            m = np.max(np.abs(covmean.imag))\n",
    "            raise ValueError(f\"Imaginary component {m}\")\n",
    "        covmean = covmean.real\n",
    "    \n",
    "    tr_covmean = np.trace(covmean)\n",
    "    \n",
    "    return (diff.dot(diff) + np.trace(sigma1) + np.trace(sigma2) - 2 * tr_covmean)\n",
    "\n",
    "def calculate_fid(real_image_dir, generated_images, batch_size=16, device='cuda'):\n",
    "    feature_extractor = InceptionV3Feature().to(device)\n",
    "\n",
    "    # Prepare real image dataset\n",
    "    real_dataset = ImageDataset(real_image_dir)\n",
    "    real_dataloader = DataLoader(real_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Save generated images to temporary directory\n",
    "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "        for i, img in enumerate(generated_images):\n",
    "            img_pil = Image.fromarray((img * 255).astype(np.uint8))\n",
    "            img_pil.save(os.path.join(tmp_dir, f\"generated_{i:04d}.png\"))\n",
    "\n",
    "        gen_dataset = ImageDataset(tmp_dir)\n",
    "        gen_dataloader = DataLoader(gen_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "        # Extract features\n",
    "        print(\"Extracting features from real images...\")\n",
    "        real_features = extract_features(feature_extractor, real_dataloader, device)\n",
    "\n",
    "        print(\"Extracting features from generated images...\")\n",
    "        gen_features = extract_features(feature_extractor, gen_dataloader, device)\n",
    "\n",
    "        # Calculate statistics\n",
    "        print(\"Calculating statistics...\")\n",
    "        mu_real, sigma_real = calculate_statistics(real_features)\n",
    "        mu_gen, sigma_gen = calculate_statistics(gen_features)\n",
    "\n",
    "        # Calculate FID\n",
    "        print(\"Calculating FID...\")\n",
    "        fid_score = calculate_frechet_distance(mu_real, sigma_real, mu_gen, sigma_gen)\n",
    "\n",
    "    return fid_score\n",
    "\n",
    "def generate_images_for_fid(model, noise_scheduler, device, num_images=100):\n",
    "    model.eval()\n",
    "    generated_images = []\n",
    "\n",
    "    print(f\"Generating {num_images} images for FID evaluation...\")\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_images):\n",
    "            noisy_image = torch.randn(1, 3, 64, 64).to(device)  # Start from random noise\n",
    "            for t in reversed(range(noise_scheduler.num_train_timesteps)):\n",
    "                noise_pred = model(noisy_image, torch.tensor([t], device=device).long()).sample\n",
    "                step_output = noise_scheduler.step(noise_pred, t, noisy_image)\n",
    "                noisy_image = step_output.prev_sample\n",
    "\n",
    "            # Denormalize and convert to numpy\n",
    "            generated_image = (noisy_image.squeeze().cpu().numpy().transpose(1, 2, 0) * 0.5 + 0.5).clip(0, 1)\n",
    "            generated_images.append(generated_image)\n",
    "\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"Generated {i + 1}/{num_images} images\")\n",
    "\n",
    "    return generated_images\n",
    "\n",
    "# Example usage\n",
    "def evaluate_diffusion_model(model, noise_scheduler, real_images_path, device, num_images=50):\n",
    "    \"\"\"\n",
    "    Evaluate diffusion model using FID metric.\n",
    "    \"\"\"\n",
    "    # Generate images\n",
    "    generated_images = generate_images_for_fid(model, noise_scheduler, device, num_images)\n",
    "    \n",
    "    # Calculate FID\n",
    "    fid_score = calculate_fid(real_images_path, generated_images, batch_size=16, device=device)\n",
    "    \n",
    "    print(f\"Final FID Score: {fid_score:.4f}\")\n",
    "    return fid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T14:15:21.276229Z",
     "iopub.status.busy": "2025-04-05T14:15:21.275921Z",
     "iopub.status.idle": "2025-04-05T14:18:49.360749Z",
     "shell.execute_reply": "2025-04-05T14:18:49.359897Z",
     "shell.execute_reply.started": "2025-04-05T14:15:21.276204Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the model using FID\n",
    "real_images_path = dataroot  # Path to real images\n",
    "evaluate_diffusion_model(model, noise_scheduler, real_images_path, device, num_images=50)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7034859,
     "sourceId": 11256481,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
